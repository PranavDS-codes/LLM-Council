import asyncio
import json
import os
import random
from typing import Optional, Any
from openai import AsyncOpenAI, APIStatusError
from config import USE_MOCK_MODE, OPENROUTER_API_KEY, OPENROUTER_BASE_URL, MODEL_MAP, OPENROUTER_SITE_URL, OPENROUTER_APP_NAME

class LLMClient:
    def __init__(self, api_key: Optional[str] = None):
        self.mock_mode = USE_MOCK_MODE
        
        # Use passed key, or fallback to env, or None
        target_key = api_key if api_key else OPENROUTER_API_KEY
        
        self.openai_client = AsyncOpenAI(
            api_key=target_key,
            base_url=OPENROUTER_BASE_URL
        ) if not self.mock_mode else None
        
    async def generate(self, prompt: str, schema: Optional[Any] = None, model: Optional[str] = None):
        """
        Generates a response from the LLM. 
        Returns (content, usage_dict).
        """
        if self.mock_mode:
            return await self._mock_generate(prompt, schema)
        
        return await self._real_generate(prompt, schema, model)

    async def _mock_generate(self, prompt: str, schema: Optional[Any] = None):
        await asyncio.sleep(0.5)
        
        usage = {"prompt": 100, "completion": 50, "total": 150}

        if "You are an impartial Senior Quality Assurance Judge" in prompt:
             return json.dumps({
                "winner_id": "Response A",
                "rankings": ["Response A", "Response B", "Response C"],
                "reasoning": "Response A provided the most depth.",
                "flaws": {"Response B": "Too brief", "Response C": "Hallucinated data"},
                "scores": {"Response A": 9, "Response B": 7, "Response C": 5}
            }), usage
        elif "You are the Chief Solutions Architect" in prompt:
            return json.dumps({
                "structure": ["Introduction", "Analysis", "Conclusion"],
                "tone_guidelines": "Professional and objective",
                "missing_facts_to_add": ["Specific dates of events"],
                "critique_integration": "Incorporate feedback on brevity."
            }), usage
        elif "You are the Finalizer" in prompt:
            return "This is the final comprehensive answer generated by the Council.", usage
        else:
            return f"Mock Response to: {prompt[:50]}...", usage

    async def _real_generate(self, prompt: str, schema: Optional[Any] = None, model: Optional[str] = None):
        target_model = model if model else MODEL_MAP.get("generator_1", "nvidia/nemotron-nano-12b-v2-vl:free")
        
        kwargs = {
            "model": target_model,
            "messages": [{"role": "user", "content": prompt}],
            "extra_headers": {
                "HTTP-Referer": OPENROUTER_SITE_URL,
                "X-Title": OPENROUTER_APP_NAME,
            },
            # Debug upstream body as requested/suggested
            # "debug": {"echo_upstream_body": True} 
        }
        
        if schema:
            kwargs["response_format"] = {"type": "json_object"}
        
        max_retries = 3
        base_delay = 2
        
        for attempt in range(max_retries + 1):
            try:
                print(f"\n[DEBUG] Sending request to OpenRouter:")
                print(f"Model: {kwargs.get('model')}")
                
                response = await self.openai_client.chat.completions.create(**kwargs)
                if not response or not response.choices:
                     raise ValueError("Received empty response or no choices from API")
                
                content = response.choices[0].message.content
                usage = {
                    "prompt": response.usage.prompt_tokens if response.usage else 0,
                    "completion": response.usage.completion_tokens if response.usage else 0,
                    "total": response.usage.total_tokens if response.usage else 0
                }
                return content, usage

            except APIStatusError as e:
                error_msg = str(e)
                print(f"[ERROR] API Status Error: {e.status_code} - {error_msg}")
                if hasattr(e, 'body'):
                    print(f"[ERROR BODY] {e.body}")

                # 422 FIX: If Unprocessable Content and we used json_object, try removing it.
                if e.status_code == 422 and "response_format" in kwargs:
                    print("[WARNING] 422 Unprocessable Content received. Retrying WITHOUT response_format constraint...")
                    del kwargs["response_format"]
                    continue

                if attempt == max_retries:
                    return f"Error calling OpenRouter after {max_retries} retries: {error_msg}", {"prompt":0, "completion":0, "total":0}
                
                # Check for retryable codes
                # Note: 422 is usually permanent unless params change, so we only filtered it above.
                if e.status_code in [429, 500, 502, 503, 504]:
                     delay = base_delay * (2 ** attempt) + (random.random() * 0.5)
                     print(f"[Warning] Server error {e.status_code}. Retrying in {delay:.2f}s...")
                     await asyncio.sleep(delay)
                     continue
                
                # If not retryable or fixed
                return f"Error calling OpenRouter: {error_msg}", {"prompt":0, "completion":0, "total":0}

            except Exception as e:
                error_msg = str(e)
                print(f"[ERROR] Generic API Call Failed: {error_msg}")
                if attempt == max_retries:
                    return f"Error calling OpenRouter after {max_retries} retries: {error_msg}", {"prompt":0, "completion":0, "total":0}
                
                # Loose check for string-based errors (legacy or other libraries)
                if "429" in error_msg or "500" in error_msg or "503" in error_msg:
                    delay = base_delay * (2 ** attempt) + (random.random() * 0.5)
                    print(f"[Warning] Error encountered. Retrying in {delay:.2f}s...")
                    await asyncio.sleep(delay)
                    continue # Try again
                
                return f"Error calling OpenRouter: {error_msg}", {"prompt":0, "completion":0, "total":0}

    async def check_connection(self, model: str) -> bool:
        """
        Validates the API connection and Model ID by making a minimal request.
        Raises specific exceptions on failure (handled by caller).
        """
        if self.mock_mode:
            await asyncio.sleep(0.5)
            # Simulate failure for specific mock models if needed, or always pass
            return True

        # Minimal generation request
        kwargs = {
            "model": model,
            "messages": [{"role": "user", "content": "Hi"}],
            "max_tokens": 1,
            "extra_headers": {
                "HTTP-Referer": OPENROUTER_SITE_URL,
                "X-Title": OPENROUTER_APP_NAME,
            }
        }
        
        # This will raise openai.APIStatusError if auth or model is invalid
        await self.openai_client.chat.completions.create(**kwargs)
        return True
